# Titanic: Machine Learning from Disaster

*Applying Machine Learning models to the classification problem - predicting the survival of the passengers on Titanic*

### Submissions made to Kaggle

1. **1.py**
	* Using pclass, sex, age, Sibsp, parch, and fare features from the available dataset
	* Using 'most frequent' strategy to replace the missing data
	* Encoding the sex column using One Hot Encoders
	* Using Kernel SVM with default parameters
	* Accuracy is 64.593%
	
2. **2.py**
	* Using pclass, sex, age, Sibsp, parch, and fare features from the available dataset
	* Using 'most frequent' strategy to replace the missing data
	* Encoding the sex column without One Hot Encoders
	* Using Kernel SVM with default parameters
	* Accuracy is 63.636%	

3. **3.py**
	* Using pclass, sex, age, Sibsp, parch, and fare features from the available dataset
	* Using 'most frequent' strategy to replace the missing data
	* Encoding the sex column (not using HotEncoders)
	* Using Naive Bayes with default parameters
	* Accuracy is 75.119%
	
4. **4.py**
	* Using pclass, sex, age, Sibsp, parch, and fare features from the available dataset
	* Using 'most frequent' strategy to replace the missing data
	* Encoding the sex column (Using OneHotEncoders)
	* Using Naive Bayes with default parameters
	* Accuracy is 76.076%